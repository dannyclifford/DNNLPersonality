{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capstone Project\n",
    "Danny Clifford\n",
    "December 31st, 2050\n",
    "\n",
    "\n",
    "# I. Definition\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "With much better memory than people and the amount of personal information we share with computers, it's amazing they don't appear to understand our personalities better.  With the exceptions of saving searches and some companies using AI and machine learning to predict profitability for advertisements, there is little effort to understand personal tendencies to cater content for (and not just to) individuals. Even those multibillion dollar corporations aim to maximize advertisment profit, not to understand the fundamental features that make each of us unique.  \n",
    "\n",
    "Understanding what connects us all, what makes each of us unique, what are our strengths and how can we harness everyone's strengths to build better lives for individuals and humanity, seem's far from the focus of their efforts.  For the first time in history, we are able to economically collect and process enough information to understand the patterns of human nature.  There have been good attempts in recent history of distinguishing the features of human processing that make certain people different than others, most notably Carl Jung in his book Psychological Types and the subsequent adaptation of his theories to the Myers Briggs Personality Index.  \n",
    "\n",
    "Carl Jung notes that it is difficult for a person who experiences their own bias to accurately judge others, joking that one person creating a system would be like creating a Universal Church with one member.  Luckily, since his time wonderful scientists such as Alan Turing, John von Neumann, J.C.R. Licklider, Miller, Moore, Noyce, and countless other have made it incredibly easy to collect, share, and calculate data from around the world almost instantly, not to mention make impressive improvements on models of understanding how agents behave.  With the addition of breakthroughs in behavioral psychology by greats like Kahnemann, Tversky, and Thaler, we are quickly building the ability to study the patterns of reason and thought in humans as differentiated by the rational agents which traditional economic theory implies.\n",
    "\n",
    "Putting these pieces together, as we communicate with computers and people, we are creating valuable information and patterns that, if only captured and studied, would give great insight into how our individual and collective minds work.  This project is about helping computers understand how the patterns in our language reflect our inner personality and in turn how we recieve, process, and communicate information.  Ultimately, computers can be our tools to help us learn our unique patterns and to help us change, supplement, or leverage how we do things to help us achieve our goals.\n",
    "\n",
    "### Problem Statement\n",
    "    \n",
    "The problem that I am setting out to solve is how to understand someone's personality based on their use of language.  If we can accurately predict one of the most fundamental aspects of a person’s behavior and uniqueness based off the language they use, the ability to communicate information to that person will be drastically improved.  The internet is designed based on information that is already programmed into the web page itself; for example, administrators see a website much differently as a new customer or even a logged in user and are determined prior to visiting the webpage. This poses a difficult design problem for web designers to incorporate designs that maximize the profit or usefulness to their intended audience rather than communicating information or value to a person on an individual basis.  If we can predict learning style or how an individual will react to their environment, then we can better customize the learning experience to their preference. \n",
    "    \n",
    "Quantifying personality has been done for us with the Myers Brigg Personality Index 4 letter code. These will be further broken down into their 4 features of a single letter with only 2 options, making it a binary choice and easy to encode the data.  In addition, it will also allow us to train the weights of determining individual features of personality in a more focused way. NLP allows algorithms to extract meaning from text whether from word count, frequency, and even parts of speech in a quantifiable and measurable way. These matrices of language data will be learned by a Neural Network and these patterns during training will be used to predict the personality features of the test group.  \n",
    "\n",
    "1. Download the data from Kaggle\n",
    "2. Let SpaCy web-medium run through the posts to make word vectors\n",
    "3. Shuffle-Split the data into testing validation and training data.\n",
    "4. Run benchmarks training and testing with Logistic Regression, Random Forest, and MLP Classifiers\n",
    "5. Run training and validation through the CNN\n",
    "5. Test accuracy of the model on the test set with AUC\n",
    "    \n",
    "    \n",
    "### Metrics\n",
    "\n",
    "Training a neural network on language use and their corresponding personality feature labels allows us to measure the AUC.  Area under the ROC curve is used to ensure the proper binary classification when it comes to specificity and sensitivity. This will help better quantify individual differences in each of the 4 personality features. Wang uses AUC in order to quantify and measure accuracy of a model.  Since the distribution of personalities within the dataset is skewed in both our datasets, this will be a good evaluation metric to use.  He also measured accuracy by comparing different models based on the features mentioned above based on AUC, not only breaking them down into dichotomous features (Sensing and Intuitive, Extrovert and Introvert), but also by focusing on features of the language.  His best individual feature was average word vectors with an AUC of 0.651, which represents this model’s ability to predict all 4 of the dichotomous personality traits.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Analysis\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "The dataset is taken from Kaggle and contains 8,600 users with 50 recent comments on the Kaggle website each and their corresponding personality type.  This was user generated data from the Kaggle website and offers the most labeled personality data connected to their text data (comments) of what I could find online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the excel document with the results\n",
    "# save it as a panda's dataframe and call it data\n",
    "data = pd.read_csv('raw/mbti_1.csv')\n",
    "\n",
    "# print out a summary of the first 5 people to make sure it worked\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first 5 entries of the Kaggle dataset. It comes with a 4 letter code called 'type' which is the person's peronality archetype according to their test results from the Myers Briggs Personality Index. Under 'posts' is a string of their most recent 50 posts on Kaggle.com separated by |||. \n",
    "\n",
    "Below is a look at the first person's entire corpus of text that we can learn from in raw form. In Data Preprocessing we will remove the links and ||| along with creating a bag of words that a the person uses that we can compare to other people and personality types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0]['posts'][:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words is a way to see how likely people are to use a word or phrase.  In Natural Language Processing (NLP), the likelihood of a word being used can be determined by how often people use the word. The likelihood of a person using a word is therefore in part determined by the similarity to the people who use the word multiplied by the likelihood of the word being said by anyone. If a person is extroverted and extroverts say a word 1% of the time and introverts 0.1% of the time; if that word is said then it is 10x more likely that it came from an extrovert.\n",
    "\n",
    "Using spaCy, \n",
    "\n",
    "Explain POS tagging\n",
    "\n",
    "Explain Weighted Average Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\n",
    "\n",
    "The bar graph below shows the distribution of the personality types in the Kaggle database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = data['type'].value_counts()\n",
    "k = data['type'].value_counts().keys()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(d.index, d.values, alpha=0.7)\n",
    "plt.ylabel('Instances', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly Introverted and/ or iNtuitive people dominate the Kaggle forums, or at least the ones participating in the creation of the database.  This will make it quite difficult to learn about those who are extroverted and sensing types (ESxx).  The model would likel minimize error by simply never predicting ESxx labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution = {}\n",
    "#actual_series = {}\n",
    "\n",
    "l = float(len(data))\n",
    "actual = [0.044, 0.015, 0.033, 0.021, 0.032, 0.081, 0.054, 0.088, 0.018, 0.116, 0.025, 0.138, 0.043, 0.085, 0.123, 0.087]\n",
    "kaggle = []\n",
    "\n",
    "for i in range(len(d)):\n",
    "    kaggle.append(float(d[i]) / l)\n",
    "\n",
    "keys = d.index.get_values()\n",
    "values = d.get_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import style \n",
    "\n",
    "fig, ax = plt.subplots(1) \n",
    "fig.autofmt_xdate()\n",
    "index = np.arange(16)\n",
    "bar_width = 7\n",
    "opacity = 0.7\n",
    "\n",
    "kaggle_bar = plt.bar(index*20, kaggle, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Kaggle')\n",
    "actual_bar = plt.bar(index*20 + bar_width, actual, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='Actual')\n",
    "\n",
    "plt.xlabel('Personality Type')\n",
    "plt.ylabel('Percentage of Population')\n",
    "plt.title('Comparing Personality Distribution of Kaggle Dataset to the World')\n",
    "plt.xticks(index*20 + bar_width, keys)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar graph above compares the percentage of people who belong to each type on the Kaggle database and Myers-Briggs world estimates.  If the data weren't already skewed enough, the people's personalities of this dataset are quite different to the general population.  When it comes to creating a system for understanding personality, the data used to train the model would ideally represent the population of personalities it is trying to understand.\n",
    "\n",
    "Insert Facets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques\n",
    "\n",
    "Preprocessing the data will be the largest part of the technique for predicting the personality of a person based on their text.  There are separating characters (|||) that need to be removed, links that will not show up in language and instead will be converted simply into the word 'link'.  \n",
    "\n",
    "As mentioned in the Data Exploration section above, using the bag of words technique to create word vectors of each personality type's language. Using spaCy's medium web language library to create relative frequencies of common language used online, the result will be a model of language use specific to each personality feature.  In addition, spaCy can find the similarities of new sentences to each corresponding personality and even between personalities.  \n",
    "\n",
    "The classifier is a Convolutional Neural Network, that will run over the language and assign the probability for each class based on their word vector representations and similarities to each personality type.\n",
    "\n",
    "Since the data is quite skewed not only from the population but especially not distributed evenly throughout the personality types, creating a model that will most accurately predict the personality type will likely result in simply guessing the most likely personality features, in this case Introverted and Intuitive (IN).  Tuning the model based on the AUC and series of 4 binary classifications (which coincidentally also makes more sense in the study of personality) allows to create the most potentially useful prediction model and avoid overfitting.  \n",
    "\n",
    "Calculating AUC not only tries to get the most predictions right, but tries to ensure that false positives and false negatives don't crop up.  In other words, since the accuracy metric would tend to create a prediction where everyone is IN__, the AUC metric will catch that the model systematically falsely assigns Extroverts the Introvert label and will look for patterns to help correct it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "\n",
    "The Benchmark I will be using to predict personality based on the data is a Logistic Regression Algoirthm with 10 fold cross validation, as I am trying to make a similar model to Yilun Wang's in his Understanding Personality through Social Media.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Methodology\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "(Just upload it from below, this takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  ['http://www.youtube.com/watch?v=qsXHcwe3krw, ...\n",
      "1  ENTP  ['I'm finding the lack of me in these posts ve...\n",
      "2  INTP  ['Good one  _____   https://www.youtube.com/wa...\n",
      "3  INTJ  ['Dear INTP,   I enjoyed our conversation the ...\n",
      "4  ENTJ  ['You're fired., That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "# Split the data at |||\n",
    "for i in range(len(data.posts)):\n",
    "    posts = data.posts[i]\n",
    "    data.posts[i] = posts.split('|||')\n",
    "    \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts  link_count\n",
      "0  INFJ  ['link, link, enfp and intj moments  link  spo...          24\n",
      "1  ENTP  ['I'm finding the lack of me in these posts ve...           9\n",
      "2  INTP  ['Good one  _____   link, Of course, to which ...           5\n",
      "3  INTJ  ['Dear INTP,   I enjoyed our conversation the ...           2\n",
      "4  ENTJ  ['You're fired., That's another silly misconce...           6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "    \n",
    "pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "data['link_count'] = 0\n",
    "df_links_list = []\n",
    "\n",
    "for i in range(len(data['posts'])):\n",
    "    cumulative_count = 0\n",
    "    for j in range(len(data.posts[i])): \n",
    "        data.posts[i][j], count = pattern.subn('link', data.posts[i][j])\n",
    "       # df_links_list.append(count)\n",
    "        cumulative_count += count\n",
    "        \n",
    "    data['link_count'][i] = cumulative_count\n",
    "            \n",
    "print(data.head())\n",
    "#print(len(df_links_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data includes looping through each post from each person and separating them into their 50 statements at the |||. Then remove the links and keep count for data visualizations later. Take the MBTI type and break it into 0/1 for I/E, S/N, F/T, and J/P respectively so we can predict individual features and functions of personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\User\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\User\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11527377521613832\n",
      "0.23054755043227665\n",
      "0.345821325648415\n",
      "0.4610951008645533\n",
      "0.5763688760806917\n",
      "0.69164265129683\n",
      "0.8069164265129684\n",
      "0.9221902017291066\n",
      "      type                                              posts  link_count  e  \\\n",
      "8670  ISFP  ['link, IxFP just because I always think of ca...           7  0   \n",
      "8671  ENFP  ['So...if this thread already exists someplace...           2  1   \n",
      "8672  INTP  ['So many questions when i do these things.  I...           2  0   \n",
      "8673  INFP  ['I am very conflicted right now when it comes...           0  0   \n",
      "8674  INFP  ['It has been too long since I have been on pe...           3  0   \n",
      "\n",
      "      n  t  p  \n",
      "8670  0  0  1  \n",
      "8671  1  0  1  \n",
      "8672  1  1  1  \n",
      "8673  1  0  1  \n",
      "8674  1  0  1  \n"
     ]
    }
   ],
   "source": [
    "word_vectors = []\n",
    "vector_norms = []\n",
    "data['e'] = 0\n",
    "data['n'] = 0\n",
    "data['t'] = 0\n",
    "data['p'] = 0\n",
    "    \n",
    "for i in range(len(data.type)):\n",
    "    persons_comments = \"\"\n",
    "    if data.type[i][0] == 'E':\n",
    "        data['e'][i] = 1\n",
    "    if data.type[i][1] == 'N':\n",
    "        data['n'][i] = 1\n",
    "    if data.type[i][2] == 'T':\n",
    "        data['t'][i] = 1\n",
    "    if data.type[i][3] == 'P':\n",
    "        data['p'][i] = 1\n",
    "    for post in data.posts[i]:\n",
    "        persons_comments += post + \" \"\n",
    "    doc = nlp(persons_comments)\n",
    "    word_vectors.append(doc.vector)\n",
    "    vector_norms.append(doc.vector_norm)\n",
    "    if i%1000 == 0:\n",
    "        print(float(i)/8675.)\n",
    "\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I can't seem to figure out how to get higher dimensional vectors to be the same shape.\n",
    "\n",
    "If not just get an entire vector representation of all the posts, which are an average of the tokens in the corpus. The shape of the doc.vector is (300,) which causes dimensionality problems. \n",
    "\n",
    "Tensors (doc.tensor) come in (x, 384) where x varies from roughly 600-1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'link\", 'link', 'enfp and intj moments  link  sportscenter not top ten plays  link  pranks', 'What\n",
      "(31, 384)\n",
      "[\"'I'm finding the lack of me in these posts very alarming.\", \"Sex can be boring if it's in the same\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-349571e9cfe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpersons_hd_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersons_hd_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "high_dim_vectors = []\n",
    "\n",
    "for i in range(10):\n",
    "    persons_hd_vectors = []\n",
    "    persons_comments = \"\"\n",
    "    #    print(data.posts[i])\n",
    "    #for post in data.posts[i]:\n",
    "    #    print(post)\n",
    "    #    persons_comments += post + \" \"\n",
    "    print(data.posts[i][:100])\n",
    "    doc = nlp(data.posts[i][:100])\n",
    "    persons_hd_vectors.append(doc.tensor)\n",
    "    print(persons_hd_vectors[].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The process for which metrics, algorithms, and techniques were implemented with the given datasets or input data has been thoroughly documented. Complications that occurred during the coding process are discussed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinement\n",
    "\n",
    "The process of improving upon the algorithms and techniques used is clearly documented. Both the initial and final solutions are reported, along with intermediate solutions, if necessary.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Validation\n",
    "\n",
    "The final model’s qualities — such as parameters — are evaluated in detail. Some type of analysis is used to validate the robustness of the model’s solution.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification\n",
    "\n",
    "The final results are compared to the benchmark result or threshold with some type of statistical analysis. Justification is made as to whether the final model and solution is significant enough to have adequately solved the problem.\n",
    "\n",
    "Although the final model performed much better than the benchmark, I would not say this solution adequately solves the problem of developing a tool to help understand people's personality through their language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectors_dict = { \"vector\"  : word_vectors,\n",
    "            \"vector_norm\"  : vector_norms\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df = pd.DataFrame.from_dict(vectors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df.to_csv('spaCy_word_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "# These are the word vectors that represent the text from all the posts of one person, index's correspond with data.index\n",
    "# Also vector_norms which are floats that I haven't been able to figure out how to use yet \n",
    "vect_df = pd.read_csv('spaCy_word_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n",
    "#scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes I don't do type. Instead, I'll predict data['t'] and calculate AUC, clearly IN are bias in this data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_vectors, data.type, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "nn_clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.3619179345320424\n",
      "RandomForestClassifier 0.24343015214384509\n",
      "MLPClassifier 0.47210696173351774\n"
     ]
    }
   ],
   "source": [
    "#X_test_train, X_test_t, y_test_train, y_test_t = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=True)\n",
    "#print(X_train.shape)\n",
    "for clf in (log_clf, rnd_clf, nn_clf): #svm_clf,\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    #auc = metrics.auc(fpr, tpr)\n",
    "    #print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTP']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Preprocessing the data will be the largest part of the technique for predicting the personality of a person based on their text. There are separating characters (|||) that need to be removed, links that will not show up in language and instead will be converted simply into the word link. As mentioned in the Data Exploration section above, using the bag of words technique to create word vectors of each personality types language. Using spaCys medium web language library to create relative frequencies of common language used online, the result will be a model of language use specific to each personality feature. In addition, spaCy can find the similarities of new sentences to each corresponding personality and even between personalities. This is a cool exploratory visualization for later. The classifier is a Convolutional Neural Network, that will run over the language and assign the probability for each class based on their word vector representations and similarities to each personality type. Since the data is quite skewed not only from the population but especially not distributed evenly throughout the personality types, creating a model that will most accurately predict the personality type will likely result in simply guessing the most likely personality features, in this case Introverted and Intuitive (IN). Tuning the model based on the AUC and series of 4 binary classifications (which coincidentally also makes more sense in the study of personality) allows to create the most potentially useful prediction model and avoid overfitting. Calculating AUC not only tries to get the most predictions right, but tries to ensure that false positives and false negatives don\\'t crop up. In other words, since the accuracy metric would tend to create a prediction where everyone is IN__, the AUC metric will catch that the model systematically falsely assigns Extroverts the Introvert label and will look for patterns to help correct it.')\n",
    "tester = doc.vector.reshape(1, -1)\n",
    "prediction = nn_clf.predict(tester)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm an ENTP and considering like 70+% of the data are introverted, pretty good guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'ENFP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-cdf24b9156e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# one-hot encode the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'ENFP'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# break training set into training and validation sets\n",
    "(x_train, x_valid) = X_train[2000:], X_train[:2000]\n",
    "(y_train, y_valid) = y_train[2000:], y_train[:2000]\n",
    "\n",
    "# print shape of training set\n",
    "#print('X_train shape:', X_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#print(x_valid.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding,LSTM\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(20000,300))  #Don't understand this part. What am I trying to input here?\n",
    "model3.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
    "model3.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 50, 299, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 25, 149, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 148, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 73, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 36, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 36, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 11,456\n",
      "Trainable params: 11,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(filters=16, kernel_size=2, activation ='relu', input_shape=(51, 300,1)))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(16, activation='softmax')) #softmax #tanh\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#train the model\n",
    "checkpointer = ModelCheckpoint(filepath='CNN.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "hist = model.fit(x_train, y_train, batch_size = 32, epochs = 20, validation=(x_valid, y_valid), callbacks=[checkpointer], verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model weights that had the best validation score\n",
    "model.load_weights('CNN.weights.best.hdf5')aaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-bf58ef6d4d42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTest accuracy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('\\nTest accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything Bbelow is just code from me messing around too much and getting off task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_word_vector = []\n",
    "\n",
    "extroverts = data.loc[data['e'] == 1]\n",
    "introverts = data.loc[data['e'] == 0]\n",
    "\n",
    "intuitive_introverts = introverts.loc[data['n'] == 1]\n",
    "intuitive_extroverts = extroverts.loc[data['n'] == 1]\n",
    "\n",
    "for i in intuitive_extroverts.index:\n",
    "    persons_comments = \"\"\n",
    "    for post in intuitive_extroverts.posts[i]:\n",
    "        persons_comments += post + \". \"\n",
    "    doc = nlp(persons_comments)\n",
    "    EN_word_vector.append(doc.vector)\n",
    "    if i%500 == 0:\n",
    "        print(i)\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(EN_word_vector, intuitive_extroverts['t'], test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "nn_clf = MLPClassifier()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, nn_clf): #svm_clf,\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(auc)\n",
    "    \n",
    "    \n",
    "IN_word_vector = []\n",
    "\n",
    "for i in intuitive_introverts.index:\n",
    "    persons_comments = \"\"\n",
    "    for post in intuitive_introverts.posts[i]:\n",
    "        persons_comments += post + \". \"\n",
    "    doc = nlp(persons_comments)\n",
    "    IN_word_vector.append(doc.vector)\n",
    "    if i%200 == 0:\n",
    "        print(i)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(IN_word_vector, intuitive_introverts['t'], test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "nn_clf = MLPClassifier()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, nn_clf): #svm_clf,\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(auc)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, nn_clf): #svm_clf,\n",
    "    y_pred = clf.predict(E_word_vector)\n",
    "    print(clf.__class__.__name__, accuracy_score(extroverts['t'], y_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(extroverts['t'], y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(auc)\n",
    "    \n",
    "    \n",
    "E_word_vector = []\n",
    "for i in extroverts.index:\n",
    "    persons_comments = \"\"\n",
    "    for post in extroverts.posts[i]:\n",
    "        persons_comments += post + \". \"\n",
    "    doc = nlp(persons_comments)\n",
    "    E_word_vector.append(doc.vector)\n",
    "    if i%500 == 0:\n",
    "        print(i)\n",
    "        \n",
    "y_pred = nn_clf.predict(E_word_vector)\n",
    "print(clf.__class__.__name__, accuracy_score(extroverts['p'], y_pred))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(extroverts['p'], y_pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Conclusion\n",
    "\n",
    "### Free Form Visualization\n",
    "\n",
    "A visualization has been provided that emphasizes an important quality about the project with thorough discussion. Visual cues are clearly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "Student adequately summarizes the end-to-end problem solution and discusses one or two particular aspects of the project they found interesting or difficult.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement\n",
    "\n",
    "\t\n",
    "Discussion is made as to how one aspect of the implementation could be improved. Potential solutions resulting from these improvements are considered and compared/contrasted to the current solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_train, X_test_t, y_test_train, y_test_t = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, nn_clf): #svm_clf,\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test_train)    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test_train, y_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_train, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(auc)\n",
    "\n",
    "nn_clf_2 = MLPClassifier()\n",
    "#train_np = np.array(X_test_train)\n",
    "#print(len(train_np))\n",
    "#guess = y_pred.tolist()\n",
    "\n",
    "print(X_test_train[0])\n",
    "\n",
    "array = y_pred.reshape(-1, 1)\n",
    "df = pd.DataFrame ({\n",
    "    'vector': np.array(X_test_train,dtype='float32'),\n",
    "    'pred'  : array\n",
    "})\n",
    "\n",
    "#print(X_test_train[:2])\n",
    "#trainer = zip(X_test_train, guess)\n",
    "#xtestrain = np.ndarray(list(trainer))\n",
    "#print(xtestrain)\n",
    "nn_clf_2.fit(array, y_test_train)\n",
    "y_pred_2 = nn_clf_2.predict(df)\n",
    "print(clf.__class__.__name__, accuracy_score(y_test_t, y_pred_2))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_train, y_pred_2, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_list = []\n",
    "df_label_list = []\n",
    "df_vector_norm_list = []\n",
    "df_post_list = []\n",
    "df_index_list = []\n",
    "e_list = []\n",
    "n_list = []\n",
    "t_list = [] \n",
    "p_list = []\n",
    "word_vectors = []\n",
    "vector_norms = []\n",
    "\n",
    "\n",
    "for i in range(len(data.type)):\n",
    "    # go through each person in the dataframe, with a fresh list of vectors for \n",
    "    #persons_comments = \"\"\n",
    "    #list_of_vectors = []\n",
    "    #list_of_vector_norms = []\n",
    "    persons_comments = \"\"\n",
    "    for post in data.posts[i]:\n",
    "        \n",
    "    label = [data.iloc[i]['e'], data.iloc[i]['n'], data.iloc[i]['t'], data.iloc[i]['p']]\n",
    "\n",
    "    for post in data.posts[i]:\n",
    "        #persons_comments += post + \". \"\n",
    "        persons_comments += post + \" \"\n",
    "\n",
    "        doc = nlp(post)\n",
    "        df_vector_list.append(doc.vector)\n",
    "        df_vector_norm_list.append(doc.vector_norm)\n",
    "        df_post_list.append(post)\n",
    "        df_index_list.append(i)\n",
    "        df_label_list.append(label)\n",
    "        e_list.append(label[0])\n",
    "        n_list.append(label[1])\n",
    "        t_list.append(label[2]) \n",
    "        p_list.append(label[3])\n",
    "    # after each post has been gone through but before the moving on to the next person\n",
    "        # I want a list of vector norms to append to df vector norm list\n",
    "        # I want a vector describing the whole corpus\n",
    "    #vector.append(doc.vector)\n",
    "    #print(vectors.dtype)\n",
    "    #data['word_vectors'][i] = vectors\n",
    "    doc = nlp(persons_comments)\n",
    "    word_vectors.append(doc.vector)\n",
    "    vector_norms.append(doc.vector_norm)\n",
    "    if i%1000 == 0:\n",
    "        print(float(i)/8675.)if i%500 == 0:\n",
    "        print(i)\n",
    "\n",
    "post_data = { 'user_id' :  df_index_list,\n",
    "              'label'   :  df_label_list,\n",
    "        'word_vector'   :  df_vector_list,\n",
    "        'vector_norm'   :  df_vector_norm_list,\n",
    "             'post'     :  df_post_list,\n",
    "             'links'    :  df_links_list\n",
    "             'e'        :  e_list,\n",
    "             'n'        :  n_list,\n",
    "             't'        :  t_list,\n",
    "             'p'        :  p_list\n",
    "            }\n",
    "post_df = pd.DataFrame.from_dict(post_data)\n",
    "print(post_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
